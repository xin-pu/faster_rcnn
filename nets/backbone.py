import torch
from torch import nn
from torchvision.models import vgg16, VGG16_Weights
import numpy as np


def get_feature_extractor():
    """
    返回VGG16的特征提取层 和 分类层
    :return:
    """
    # the 30th layer of features is relu of conv5_3
    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)

    # noinspection PyTypeChecker
    feature_lay = list(model.features)[:30]

    # freeze top4 conv
    for layer in feature_lay[:10]:
        for p in layer.parameters():
            p.requires_grad = False
    faster_rcnn_fe_extractor = nn.Sequential(*feature_lay)
    return faster_rcnn_fe_extractor


def generate_anchor_base(base_size=16,
                         ratios=(0.5, 1, 2),
                         anchor_scales=(8, 16, 32)):
    """Generate anchor base windows by enumerating aspect ratio and scales.

    Generate anchors that are scaled and modified to the given aspect ratios.
    Area of a scaled anchor is preserved when modifying to the given aspect
    ratio.

    :obj:`R = len(ratios) * len(anchor_scales)` anchors are generated by this
    function.
    The :obj:`i * len(anchor_scales) + j` th anchor corresponds to an anchor
    generated by :obj:`ratios[i]` and :obj:`anchor_scales[j]`.

    For example, if the scale is :math:`8` and the ratio is :math:`0.25`,
    the width and the height of the base window will be stretched by :math:`8`.
    For modifying the anchor to the given aspect ratio,
    the height is halved and the width is doubled.

    Args:
        base_size (number): The width and the height of the reference window.
        ratios (list of floats): This is ratios of width to height of
            the anchors.
        anchor_scales (list of numbers): This is areas of anchors.
            Those areas will be the product of the square of an element in
            :obj:`anchor_scales` and the original area of the reference
            window.

    Returns:
        ~numpy.ndarray:
        An array of shape :math:`(R, 4)`.
        Each element is a set of coordinates of a bounding box.
        The second axis corresponds to
        :math:`(y_{min}, x_{min}, y_{max}, x_{max})` of a bounding box.

    """
    py = base_size / 2.
    px = base_size / 2.

    anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4))
    for i in range(len(ratios)):
        for j in range(len(anchor_scales)):
            h = base_size * anchor_scales[j] * np.sqrt(ratios[i])
            w = base_size * anchor_scales[j] * np.sqrt(1. / ratios[i])

            index = i * len(anchor_scales) + j
            anchor_base[index, 0] = py - h / 2.
            anchor_base[index, 1] = px - w / 2.
            anchor_base[index, 2] = py + h / 2.
            anchor_base[index, 3] = px + w / 2.
    return anchor_base


if __name__ == "__main__":
    # feature shape should be [batch, 512, M, N]
    # When Image size is [800,800] => M=50,N=50
    # So RPN Input Unit is 512
    feature_extractor = get_feature_extractor()
    images = torch.Tensor(1, 3, 800, 800)
    features = feature_extractor(images)
    print(features)

    # anchors: [9,4]
    anchors = generate_anchor_base(base_size=16)
    print(anchors)
